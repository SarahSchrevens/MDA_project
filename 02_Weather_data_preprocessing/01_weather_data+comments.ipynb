{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3250480a",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #data visualization\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add40e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parser() fun is useful when you have a string representing a date and time in a specific format\n",
    "#and you want to convert it into a DateTime object for further manipulation and analysis using pandas\n",
    "def parser(s):\n",
    "    return pd.to_datetime(s, format='%d/%m/%Y %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f63d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meteo Data\n",
    "#four quarterly data files for the year 2022 are read\n",
    "LC_01 = pd.read_csv(\"dataverse_files/LC_2022Q1.csv\")\n",
    "LC_02 = pd.read_csv(\"dataverse_files/LC_2022Q2.csv\")\n",
    "LC_03 = pd.read_csv(\"dataverse_files/LC_2022Q3.csv\")\n",
    "LC_04 = pd.read_csv(\"dataverse_files/LC_2022Q4.csv\")\n",
    "Meta = pd.read_csv(\"dataverse_files/01_Metadata_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines the data for specific IDs (LC-065, LC-087, LC-102, LC-109, LC-112, LC-117, LC-118) \n",
    "#from the quarterly meteorological DataFrames (LC_01, LC_02, LC_03, LC_04) \n",
    "#into separate DataFrames (LC_065, LC_087, LC_102, LC_109, LC_112, LC_117, LC_118)\n",
    "\n",
    "LC_065 = pd.concat([LC_01[LC_01[\"ID\"]==\"LC-065\"], LC_02[LC_02[\"ID\"]==\"LC-065\"], LC_03[LC_03[\"ID\"]==\"LC-065\"], LC_04[LC_04[\"ID\"]==\"LC-065\"]], axis=0).reset_index(drop=True)\n",
    "LC_087 = pd.concat([LC_01[LC_01[\"ID\"]==\"LC-087\"], LC_02[LC_02[\"ID\"]==\"LC-087\"], LC_03[LC_03[\"ID\"]==\"LC-087\"], LC_04[LC_04[\"ID\"]==\"LC-087\"]], axis=0).reset_index(drop=True)\n",
    "LC_102 = pd.concat([LC_01[LC_01[\"ID\"]==\"LC-102\"], LC_02[LC_02[\"ID\"]==\"LC-102\"], LC_03[LC_03[\"ID\"]==\"LC-102\"], LC_04[LC_04[\"ID\"]==\"LC-102\"]], axis=0).reset_index(drop=True)\n",
    "LC_109 = pd.concat([LC_01[LC_01[\"ID\"]==\"LC-109\"], LC_02[LC_02[\"ID\"]==\"LC-109\"], LC_03[LC_03[\"ID\"]==\"LC-109\"], LC_04[LC_04[\"ID\"]==\"LC-109\"]], axis=0).reset_index(drop=True)\n",
    "LC_112 = pd.concat([LC_01[LC_01[\"ID\"]==\"LC-112\"], LC_02[LC_02[\"ID\"]==\"LC-112\"], LC_03[LC_03[\"ID\"]==\"LC-112\"], LC_04[LC_04[\"ID\"]==\"LC-112\"]], axis=0).reset_index(drop=True)\n",
    "LC_117 = pd.concat([LC_01[LC_01[\"ID\"]==\"LC-117\"], LC_02[LC_02[\"ID\"]==\"LC-117\"], LC_03[LC_03[\"ID\"]==\"LC-117\"], LC_04[LC_04[\"ID\"]==\"LC-117\"]], axis=0).reset_index(drop=True)\n",
    "LC_118 = pd.concat([LC_01[LC_01[\"ID\"]==\"LC-118\"], LC_02[LC_02[\"ID\"]==\"LC-118\"], LC_03[LC_03[\"ID\"]==\"LC-118\"], LC_04[LC_04[\"ID\"]==\"LC-118\"]], axis=0).reset_index(drop=True)\n",
    "\n",
    "#The pd.concat() function is used to concatenate the rows with matching IDs from each quarterly DataFrame. \n",
    "#The axis=0 parameter specifies that the concatenation should be done along the rows (vertically). \n",
    "#The reset_index(drop=True) part resets the index of the concatenated DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffee948",
   "metadata": {},
   "source": [
    "### averaging data of 7 weather stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d903924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list with all dataframes\n",
    "dfs = [LC_065, LC_087, LC_102, LC_109, LC_112, LC_117, LC_118]\n",
    "\n",
    "#initialize the merged_df variable with the first DataFrame from the list, LC_065 \n",
    "#and list of suffixes to be used when merging the DataFrames\n",
    "merged_df = dfs[0]\n",
    "suffixes = ['', '_2', '_3', '_4', '_5', '_6', '_7']\n",
    "\n",
    "#It loops through the remaining DataFrames (dfs[1:]) and merges each DataFrame with the merged_df DataFrame \n",
    "#based on the \"DATEUTC\" column using an inner join. The suffixes are applied\n",
    "# [index start from 1]\n",
    "for i, df in enumerate(dfs[1:], start=1):\n",
    "    merged_df = pd.merge(merged_df, df, on='DATEUTC', how='inner', suffixes=('', suffixes[i]))\n",
    "\n",
    "# list of columns to average\n",
    "columns_to_average = [\"LC_HUMIDITY\", \"LC_DWPTEMP\", \"LC_n\", \"LC_RAD\", \"LC_RAININ\", \"LC_DAILYRAIN\", \"LC_WINDDIR\", \"LC_WINDSPEED\", \"LC_RAD60\", \"LC_TEMP_QCL0\", \"LC_TEMP_QCL1\", \"LC_TEMP_QCL2\", \"LC_TEMP_QCL3\"]\n",
    "\n",
    "#create a dictionary average_columns that maps each column name to the mean of corresponding columns with suffixes in the merged_df DataFrame\n",
    "average_columns = {col: merged_df[[f\"{col}{suffix}\" for suffix in suffixes]].mean(axis=1) for col in columns_to_average}\n",
    "# dataframe of averages\n",
    "average_df = pd.DataFrame(average_columns)\n",
    "\n",
    "#add additional columns to average_df based on the values derived from 'DATEUTC'\n",
    "average_df['DATEUTC'] = merged_df['DATEUTC']\n",
    "average_df[\"ID\"] = \"AVE\"\n",
    "average_df['Date'] = pd.to_datetime(average_df['DATEUTC']).dt.strftime('%Y/%m/%d')\n",
    "average_df['Year'] = pd.to_datetime(average_df['DATEUTC']).dt.year\n",
    "average_df['Month'] = pd.to_datetime(average_df['DATEUTC']).dt.month\n",
    "average_df['Day'] = pd.to_datetime(average_df['DATEUTC']).dt.day\n",
    "average_df['Hour'] = pd.to_datetime(average_df['DATEUTC']).dt.hour\n",
    "average_df['Minute'] = pd.to_datetime(average_df['DATEUTC']).dt.minute\n",
    "\n",
    "#reoder columns\n",
    "reorder_columns = [\"DATEUTC\", \"ID\", \"LC_HUMIDITY\", \"LC_DWPTEMP\", \"LC_n\", \"LC_RAD\", \"LC_RAININ\", \"LC_DAILYRAIN\", \"LC_WINDDIR\", \"LC_WINDSPEED\", \"Date\", \"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"LC_RAD60\", \"LC_TEMP_QCL0\", \"LC_TEMP_QCL1\", \"LC_TEMP_QCL2\", \"LC_TEMP_QCL3\"]\n",
    "\n",
    "#assign reordered average_df to the variable average_df\n",
    "average_df = average_df[reorder_columns]\n",
    "\n",
    "average_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create csv\n",
    "average_df.to_csv('LC_2022_Ave.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c9792",
   "metadata": {},
   "source": [
    "### weather data analysit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c222de",
   "metadata": {},
   "source": [
    "LC_RAININ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f180e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#line plot showing the \"LC_RAININ\" data for each  dataframe\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(LC_065[\"LC_RAININ\"], label=\"LC-065\")\n",
    "plt.plot(LC_087[\"LC_RAININ\"], label=\"LC-087\")\n",
    "plt.plot(LC_102[\"LC_RAININ\"], label=\"LC-102\")\n",
    "plt.plot(LC_109[\"LC_RAININ\"], label=\"LC-109\")\n",
    "plt.plot(LC_112[\"LC_RAININ\"], label=\"LC-112\")\n",
    "plt.plot(LC_117[\"LC_RAININ\"], label=\"LC-117\")\n",
    "plt.plot(LC_118[\"LC_RAININ\"], label=\"LC-118\")\n",
    "\n",
    "plt.xlabel(\"Index\") #x axis represents index values\n",
    "plt.ylabel(\"LC_RAININ\") #y axis represents rain\n",
    "plt.legend()\n",
    "plt.title(\"LC_RAININ for 7 Dataframes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec0d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine \"LC_RAININ\" columns from the seven DataFrames into a new DataFrame and assign names to columns\n",
    "df_combined = pd.concat([LC_065[\"LC_RAININ\"], LC_087[\"LC_RAININ\"], LC_102[\"LC_RAININ\"], LC_109[\"LC_RAININ\"], LC_112[\"LC_RAININ\"], LC_117[\"LC_RAININ\"], LC_118[\"LC_RAININ\"]], axis=1)\n",
    "df_combined.columns = [\"LC_RAININ1\", \"LC_RAININ2\", \"LC_RAININ3\", \"LC_RAININ4\", \"LC_RAININ5\", \"LC_RAININ6\", \"LC_RAININ7\"]\n",
    "df_combined = df_combined.dropna() #drop missings\n",
    "\n",
    "#concatenation along columns because axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform paired t-tests between different combinations of the \"LC_RAININ\" columns in the df_combined DataFrame. \n",
    "#It calculates the t-statistic and p-value for each pairwise comparison and prints the results\n",
    "\n",
    "from itertools import combinations #iteration and combination of elements\n",
    "from scipy.stats import ttest_rel #provides various statistical functions and distributions lie t-test\n",
    "\n",
    "for combo in combinations(range(1, 8), 2): #generate all possible combinations of two numbers from the range 1 to 7 \n",
    "    #t-statistic and p-value are assigned to the variables t_stat and p_value\n",
    "    t_stat, p_value = ttest_rel(df_combined[f\"LC_RAININ{combo[0]}\"], df_combined[f\"LC_RAININ{combo[1]}\"]) \n",
    "    #results are printed using formatted strings to display the column names being compared\n",
    "    print(f\"LC_RAININ{combo[0]} vs LC_RAININ{combo[1]}: t-statistic = {t_stat}, p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe6c703",
   "metadata": {},
   "source": [
    "LC_TEMP_QCL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAME as above\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(LC_065[\"LC_TEMP_QCL3\"], label=\"LC-065\")\n",
    "plt.plot(LC_087[\"LC_TEMP_QCL3\"], label=\"LC-087\")\n",
    "plt.plot(LC_102[\"LC_TEMP_QCL3\"], label=\"LC-102\")\n",
    "plt.plot(LC_109[\"LC_TEMP_QCL3\"], label=\"LC-109\")\n",
    "plt.plot(LC_112[\"LC_TEMP_QCL3\"], label=\"LC-112\")\n",
    "plt.plot(LC_117[\"LC_TEMP_QCL3\"], label=\"LC-117\")\n",
    "plt.plot(LC_118[\"LC_TEMP_QCL3\"], label=\"LC-118\")\n",
    "\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"LC_TEMP_QCL3\")\n",
    "plt.legend()\n",
    "plt.title(\"LC_RAININ for 7 Dataframes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af519c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAME as above\n",
    "\n",
    "df_combined = pd.concat([LC_065[\"LC_TEMP_QCL3\"], LC_087[\"LC_TEMP_QCL3\"], LC_102[\"LC_TEMP_QCL3\"], LC_109[\"LC_TEMP_QCL3\"], LC_112[\"LC_TEMP_QCL3\"], LC_117[\"LC_TEMP_QCL3\"], LC_118[\"LC_TEMP_QCL3\"]], axis=1)\n",
    "df_combined.columns = [\"LC_TEMP_QCL31\", \"LC_TEMP_QCL32\", \"LC_TEMP_QCL33\", \"LC_TEMP_QCL34\", \"LC_TEMP_QCL35\", \"LC_TEMP_QCL36\", \"LC_TEMP_QCL37\"]\n",
    "df_combined = df_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12475b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAME as above\n",
    "\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "for combo in combinations(range(1, 8), 2):\n",
    "    t_stat, p_value = ttest_rel(df_combined[f\"LC_TEMP_QCL3{combo[0]}\"], df_combined[f\"LC_TEMP_QCL3{combo[1]}\"])\n",
    "    print(f\"LC_TEMP_QCL3{combo[0]} vs LC_TEMP_QCL3{combo[1]}: t-statistic = {t_stat}, p-value = {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
